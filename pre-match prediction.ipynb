{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bfe7169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scikitplot as skplt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9e88f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('playerid.csv')\n",
    "averages = pd.read_csv('player_averages.csv')\n",
    "columns = ['SP', 'RP', 'SRP', 'LRP', 'FHP', 'BHP', 'RANKDIFF', 'SA', 'SRA', 'FHA', 'BALANCE', 'Player ID']\n",
    "XID = data[columns]\n",
    "X = XID.drop(columns='Player ID')\n",
    "y = data.WON\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, train_size=0.9, random_state=1)\n",
    "X_trainval1, X_test1, y_trainval1, y_test1 = train_test_split(XID, y, train_size=0.9, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c4a5ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = X_test1['Player ID'].values.tolist()\n",
    "ls = []\n",
    "\n",
    "for i in ids:\n",
    "    a = (averages.loc[averages['Player ID'] == i]).values.tolist()[0]\n",
    "    ls.append(a)\n",
    "\n",
    "new_test = pd.DataFrame(np.array(ls),columns=['SP', 'RP', 'SRP', 'LRP', 'FHP', 'BHP', 'RANK', 'RANKDIFF', 'SA', 'SRA', 'FHA', 'BALANCE', 'Player ID'])\n",
    "new_test = new_test.drop(columns='Player ID')\n",
    "new_test = new_test.drop(columns='RANK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4835ff91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-523a752f028e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscores1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trainval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trainval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Scores 5F CV\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "model = SVC(C=0.2, gamma=1, kernel='linear', random_state=1) \n",
    "\n",
    "print(\"Validation Set\")\n",
    "scores1 = cross_val_score(model, X_trainval, y_trainval, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy Scores 5F CV\")\n",
    "print(scores1)\n",
    "scores1 = pd.Series(scores1)\n",
    "print(\"mean:\",scores1.mean(), \"ste:\", (np.std(scores1))/math.sqrt(5))\n",
    "print(\"\")\n",
    "print(\"F1 Scores 5F CV\")\n",
    "scores2 = cross_val_score(model, X_trainval, y_trainval, cv=5, scoring='f1')\n",
    "print(scores2)\n",
    "scores1 = pd.Series(scores2)\n",
    "print(\"mean:\",scores2.mean(), \"ste:\", (np.std(scores1))/math.sqrt(5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Test Set\")\n",
    "model.fit(X_trainval, y_trainval)\n",
    "y_pred = model.predict(new_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score:\", metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf9acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
